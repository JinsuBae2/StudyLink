package com.example.backend.service;

import com.example.backend.dto.studygroup.RecommendedStudyGroupDto;
import com.example.backend.entity.StudyGroup;
import com.example.backend.entity.User;
import com.example.backend.repository.StudyGroupRepository;
import com.example.backend.repository.UserRepository;
import lombok.RequiredArgsConstructor;
import org.springframework.security.core.userdetails.UserDetails;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.util.*;
import java.util.stream.Collectors;

@Service
@RequiredArgsConstructor
public class RecommendationService {

    private final UserRepository userRepository;
    private final StudyGroupRepository studyGroupRepository;

    private static final Set<String> STOP_WORDS = Set.of(
            "ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ìœ¼ë¡œ", "ë¡œ", "ì™€", "ê³¼", "ë„", "ë§Œ", "ì¢€", "ì˜", "ë”",
            "ê°€ì¥", "ì•„ì£¼", "ì •ë§", "ë°”ë¡œ", "ê·¸ë¦¬ê³ ", "ê·¸ë˜ì„œ", "ê·¸ëŸ¬ë‚˜", "í•˜ì§€ë§Œ", "ë˜ëŠ”", "ë°", "ì¦‰", "ë“±",
            "ê²ƒ", "ìˆ˜", "ìˆìŠµë‹ˆë‹¤", "í•©ë‹ˆë‹¤", "ì´ë‹¤", "ìœ„í•´", "ëŒ€í•œ", "í†µí•´"
    );

    @Transactional(readOnly = true)
    public List<RecommendedStudyGroupDto> recommendGroupsByContent(UserDetails userDetails) {
        User currentUser = userRepository.findByEmail(userDetails.getUsername())
                .orElseThrow(() -> new IllegalArgumentException("ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."));

        List<StudyGroup> allStudyGroups = studyGroupRepository.findAll();

        // 1. ì „ì²´ ë¬¸ì„œ(í•™ìŠµ ëª©í‘œ í…ìŠ¤íŠ¸) ìˆ˜ì§‘
        List<String> allGoals = new ArrayList<>();
        allStudyGroups.forEach(sg -> allGoals.add(sg.getGoal()));
        allGoals.add(currentUser.getGoal());

        // 2. IDF ì–´íœ˜ ì‚¬ì „ ìƒì„±
        Map<String, Double> idfVocabulary = calculateIdf(allGoals);

        // 3. í˜„ì¬ ì‚¬ìš©ìì˜ TF-IDF ë²¡í„° ìƒì„±
        Map<String, Double> userTfIdfVector = createTfIdfVector(currentUser.getGoal(), idfVocabulary);

        // 4. ê° ìŠ¤í„°ë”” ê·¸ë£¹ê³¼ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ë° ì •ë ¬
        return allStudyGroups.stream()
                .map(studyGroup -> {
                    Map<String, Double> groupTfIdfVector = createTfIdfVector(studyGroup.getGoal(), idfVocabulary);
                    double similarity = calculateCosineSimilarity(userTfIdfVector, groupTfIdfVector);
                    return new RecommendedStudyGroupDto(studyGroup, similarity * 100); // ì ìˆ˜ë¥¼ 100ì  ë§Œì ìœ¼ë¡œ ë³€í™˜
                })
                .filter(dto -> dto.getMatchScore() > 0) // ìœ ì‚¬ë„ê°€ 0 ì´ìƒì¸ ê²ƒë§Œ
                .sorted(Comparator.comparing(RecommendedStudyGroupDto::getMatchScore).reversed())
                .collect(Collectors.toList());
    }

    // --- TF-IDF ë° ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°ì„ ìœ„í•œ private í—¬í¼ ë©”ì†Œë“œë“¤ ---

    // TF-IDF ë²¡í„° ìƒì„± (TF * IDF)
    private Map<String, Double> createTfIdfVector(String text, Map<String, Double> idfVocabulary) {
        if (text == null || text.isBlank()) {
            return Collections.emptyMap();
        }
        List<String> tokens = tokenize(text);
        Map<String, Long> tf = calculateTf(tokens);

        Map<String, Double> tfIdfVector = new HashMap<>();
        for (String term : tf.keySet()) {
            if (idfVocabulary.containsKey(term)) {
                double tfIdf = tf.get(term) * idfVocabulary.get(term);
                tfIdfVector.put(term, tfIdf);
            }
        }
        return tfIdfVector;
    }

    // IDF ê³„ì‚°: log(ì „ì²´ ë¬¸ì„œ ìˆ˜ / í•´ë‹¹ ë‹¨ì–´ê°€ í¬í•¨ëœ ë¬¸ì„œ ìˆ˜)
    private Map<String, Double> calculateIdf(List<String> documents) {
        Map<String, Double> idf = new HashMap<>();
        Set<String> allTerms = new HashSet<>();
        List<Set<String>> docTermsList = new ArrayList<>();

        for (String doc : documents) {
            if (doc == null || doc.isBlank()) continue;
            Set<String> terms = new HashSet<>(tokenize(doc));
            allTerms.addAll(terms);
            docTermsList.add(terms);
        }

        int totalDocuments = documents.size();
        for (String term : allTerms) {
            long docCountWithTerm = docTermsList.stream().filter(docTerms -> docTerms.contains(term)).count();
            double idfValue = Math.log((double) totalDocuments / (docCountWithTerm + 1)); // +1ì€ 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì„ ë°©ì§€
            idf.put(term, idfValue);
        }
        return idf;
    }

    // TF ê³„ì‚°: (ë¬¸ì„œ ë‚´ íŠ¹ì • ë‹¨ì–´ ìˆ˜) / (ë¬¸ì„œ ë‚´ ì „ì²´ ë‹¨ì–´ ìˆ˜)
    private Map<String, Long> calculateTf(List<String> tokens) {
        return tokens.stream().collect(Collectors.groupingBy(token -> token, Collectors.counting()));
    }

    // ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ í† í°í™”
    private List<String> tokenize(String text) {
        if (text == null || text.isBlank()) {
            return Collections.emptyList();
        }
        return Arrays.stream(
                        text.toLowerCase() // ì†Œë¬¸ì ë³€í™˜
                                .replaceAll("[^a-zA-Z0-9ê°€-í£\\s]", "") // íŠ¹ìˆ˜ë¬¸ì ì œê±°
                                .split("\\s+")) // ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬
                .filter(token -> !token.isBlank() && !STOP_WORDS.contains(token)) // ğŸ‘ˆ ë¶ˆìš©ì–´ ì œê±°!
                .collect(Collectors.toList());
    }

    // ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    private double calculateCosineSimilarity(Map<String, Double> vec1, Map<String, Double> vec2) {
        if (vec1.isEmpty() || vec2.isEmpty()) {
            return 0.0;
        }

        Set<String> intersection = new HashSet<>(vec1.keySet());
        intersection.retainAll(vec2.keySet());

        double dotProduct = 0.0;
        for (String key : intersection) {
            dotProduct += vec1.get(key) * vec2.get(key);
        }

        double norm1 = 0.0;
        for (double value : vec1.values()) {
            norm1 += Math.pow(value, 2);
        }
        norm1 = Math.sqrt(norm1);

        double norm2 = 0.0;
        for (double value : vec2.values()) {
            norm2 += Math.pow(value, 2);
        }
        norm2 = Math.sqrt(norm2);

        if (norm1 == 0.0 || norm2 == 0.0) {
            return 0.0;
        }

        return dotProduct / (norm1 * norm2);
    }
}